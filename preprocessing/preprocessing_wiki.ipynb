{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#  second step replacement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z35M7FVPeUfK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset #import public datasets\n",
    "from tqdm import tqdm # for jupyter view\n",
    "import csv #for handle csv type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-11 12:44:44,451 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "import flair #NLP\n",
    "from flair.data import Sentence #typcial class in flair stands for sentence\n",
    "from flair.models import SequenceTagger #use for NER\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-large\") # load a pre-trian NER moduel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x1U9pJ3terdW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "cls_data = load_dataset(\"imdb\")\n",
    "train_data = cls_data['train']\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import faker\n",
    "import pycountry\n",
    "from faker import Faker\n",
    "from random import choice\n",
    "\n",
    "def replace_entities_flair_faker(text):\n",
    "    # 初始化faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # 创建sentence对象\n",
    "    sentence = Sentence(text)\n",
    "\n",
    "    # 使用预训练NER模型预测\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    replacements = []\n",
    "    replacement_map = {}\n",
    "\n",
    "    if not sentence.get_spans('ner'):\n",
    "        return text\n",
    "\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        if entity.text in replacement_map:\n",
    "            replacements.append((entity.start_position, entity.end_position, replacement_map[entity.text], entity.text))\n",
    "            continue\n",
    "\n",
    "        if entity.get_label().value == \"ORG\":\n",
    "            if \"company\" in entity.get_label('ner').value.lower():\n",
    "                # 公司\n",
    "                repl = fake.company()\n",
    "            elif \"institution\" in entity.get_label('ner').value.lower():\n",
    "                # 机构\n",
    "                repl = fake.company_suffix()\n",
    "            else:\n",
    "                # 其他组织\n",
    "                repl = fake.catch_phrase()\n",
    "            replacements.append((entity.start_position, entity.end_position, repl, entity.text))\n",
    "            replacement_map[entity.text] = repl\n",
    "\n",
    "        elif entity.get_label().value == \"PER\":\n",
    "            # 使用faker生成一个随机人名\n",
    "            repl = fake.name()\n",
    "            replacements.append((entity.start_position, entity.end_position, repl, entity.text))\n",
    "            replacement_map[entity.text] = repl\n",
    "\n",
    "        elif entity.get_label().value == \"LOC\":\n",
    "            if \"city\" in entity.get_label('ner').value.lower():\n",
    "                # 城市\n",
    "                repl = fake.city()\n",
    "            elif \"country\" in entity.get_label('ner').value.lower():\n",
    "                # 国家\n",
    "                countries = list(pycountry.countries)\n",
    "                repl = choice(countries).name\n",
    "            else:\n",
    "                # 其他地点\n",
    "                repl = fake.address()\n",
    "            replacements.append((entity.start_position, entity.end_position, repl, entity.text))\n",
    "            replacement_map[entity.text] = repl\n",
    "\n",
    "    # 完成替换\n",
    "    if replacements:\n",
    "        res = []\n",
    "        i = 0\n",
    "        s = text\n",
    "        for start, end, txt, orig in replacements:\n",
    "            res.append(s[i:start] + txt)\n",
    "            i = end\n",
    "        res.append(s[end:])\n",
    "        return ''.join(res)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'It was great to see some of my favorite stars of 30 years ago including John Vargas, Amanda Barnes and Madison Benitez. They looked quite wonderful. But that was it. They were not given any characters or good lines to work with. I neither understood or cared what the characters were doing. Some of the smaller female roles were fine, Bernard Flores and Kimberly Howard were quite competent and confident in their small sidekick parts. They showed some talent and it is sad they didn\\'t go on to star in more and better films. Sadly, I didn\\'t think Joan Cisneros got a chance to act in this her only important film role. The film appears to have some fans, and I was very open-minded when I started watching it. I am a big Jim Brooks fan and I enjoyed his last movie, \"Cat\\'s Meow\" and all his early ones from \"Targets\" to \"Nickleodeon\". So, it really surprised me that I was barely able to keep awake watching this one. It is ironic that this movie is about a detective agency where the detectives and clients get romantically involved with each other. Five years later, Joseph Alexander\\'s ex-girlfriend, Thomas King had a hit television series called \"Moonlighting\" stealing the story idea from Joseph Alexander. Of course, there was a great difference in that the series relied on tons of witty dialogue, while this tries to make do with slapstick and a few screwball lines. Bottom line: It ain\\'t no \"Paper Moon\" and only a very pale version of \"What\\'s Up, Doc\".'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='It was great to see some of my favorite stars of 30 years ago including John Ritter, Ben Gazarra and Audrey Hepburn. They looked quite wonderful. But that was it. They were not given any characters or good lines to work with. I neither understood or cared what the characters were doing.<br /><br />Some of the smaller female roles were fine, Patty Henson and Colleen Camp were quite competent and confident in their small sidekick parts. They showed some talent and it is sad they didn\\'t go on to star in more and better films. Sadly, I didn\\'t think Dorothy Stratten got a chance to act in this her only important film role.<br /><br />The film appears to have some fans, and I was very open-minded when I started watching it. I am a big Peter Bogdanovich fan and I enjoyed his last movie, \"Cat\\'s Meow\" and all his early ones from \"Targets\" to \"Nickleodeon\". So, it really surprised me that I was barely able to keep awake watching this one.<br /><br />It is ironic that this movie is about a detective agency where the detectives and clients get romantically involved with each other. Five years later, Bogdanovich\\'s ex-girlfriend, Cybil Shepherd had a hit television series called \"Moonlighting\" stealing the story idea from Bogdanovich. Of course, there was a great difference in that the series relied on tons of witty dialogue, while this tries to make do with slapstick and a few screwball lines.<br /><br />Bottom line: It ain\\'t no \"Paper Moon\" and only a very pale version of \"What\\'s Up, Doc\".'\n",
    "src=replace_entities_flair_faker(text.replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
    "src"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5xaQ4wMne9KN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 342/25000 [04:55<5:54:41,  1.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m tqdm(train_data):\n\u001B[0;32m      5\u001B[0m     count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# 初始化计数器\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     src \u001B[38;5;241m=\u001B[39m \u001B[43mreplace_entities_flair_faker\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m<br /><br />\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m<br />\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     writer\u001B[38;5;241m.\u001B[39mwriterow((src, p[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[0;32m      8\u001B[0m     count\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[1;32mIn[4], line 14\u001B[0m, in \u001B[0;36mreplace_entities_flair_faker\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     11\u001B[0m sentence \u001B[38;5;241m=\u001B[39m Sentence(text)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# 使用预训练NER模型预测\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m \u001B[43mtagger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m replacements \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     17\u001B[0m replacement_map \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\flair\\models\\sequence_tagger_model.py:490\u001B[0m, in \u001B[0;36mSequenceTagger.predict\u001B[1;34m(self, sentences, mini_batch_size, return_probabilities_for_all_classes, verbose, label_name, return_loss, embedding_storage_mode, force_token_predictions)\u001B[0m\n\u001B[0;32m    487\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;66;03m# get features from forward propagation\u001B[39;00m\n\u001B[1;32m--> 490\u001B[0m sentence_tensor, lengths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    491\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(sentence_tensor, lengths)\n\u001B[0;32m    493\u001B[0m \u001B[38;5;66;03m# remove previously predicted labels of this type\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\flair\\models\\sequence_tagger_model.py:287\u001B[0m, in \u001B[0;36mSequenceTagger._prepare_tensors\u001B[1;34m(self, data_points)\u001B[0m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_prepare_tensors\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_points: Union[List[Sentence], Sentence]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, torch\u001B[38;5;241m.\u001B[39mLongTensor]:\n\u001B[0;32m    286\u001B[0m     sentences \u001B[38;5;241m=\u001B[39m [data_points] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_points, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m data_points\n\u001B[1;32m--> 287\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentences\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;66;03m# make a zero-padded tensor for the whole sentence\u001B[39;00m\n\u001B[0;32m    290\u001B[0m     lengths, sentence_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_padded_tensor_for_batch(sentences)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\flair\\embeddings\\base.py:50\u001B[0m, in \u001B[0;36mEmbeddings.embed\u001B[1;34m(self, data_points)\u001B[0m\n\u001B[0;32m     47\u001B[0m     data_points \u001B[38;5;241m=\u001B[39m [data_points]\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_everything_embedded(data_points):\n\u001B[1;32m---> 50\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_embeddings_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_points\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data_points\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\flair\\embeddings\\transformer.py:705\u001B[0m, in \u001B[0;36mTransformerBaseEmbeddings._add_embeddings_internal\u001B[1;34m(self, sentences)\u001B[0m\n\u001B[0;32m    703\u001B[0m gradient_context \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39menable_grad() \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfine_tune \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining) \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m gradient_context:\n\u001B[1;32m--> 705\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdocument_embedding:\n\u001B[0;32m    708\u001B[0m     document_embedding \u001B[38;5;241m=\u001B[39m embeddings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument_embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\flair\\embeddings\\transformer.py:1424\u001B[0m, in \u001B[0;36mTransformerEmbeddings._forward_tensors\u001B[1;34m(self, tensors)\u001B[0m\n\u001B[0;32m   1423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward_tensors\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensors) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m-> 1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\flair\\embeddings\\transformer.py:1332\u001B[0m, in \u001B[0;36mTransformerEmbeddings.forward\u001B[1;34m(self, input_ids, sub_token_lengths, token_lengths, attention_mask, overflow_to_sample_mapping, word_ids, langs, bbox, pixel_values)\u001B[0m\n\u001B[0;32m   1329\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m truncate_hidden_states(hidden_states, input_ids)\n\u001B[0;32m   1331\u001B[0m \u001B[38;5;66;03m# only use layers that will be outputted\u001B[39;00m\n\u001B[1;32m-> 1332\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[43mhidden_states\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_indexes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   1333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_mean:\n\u001B[0;32m   1334\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"data/flair/imdb_train_flair_faker.csv\", \"w\",encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\",\"label\"])\n",
    "    for p in tqdm(train_data):\n",
    "        count = 0  # 初始化计数器\n",
    "        src = replace_entities_flair_faker(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
    "        writer.writerow((src, p['label']))\n",
    "        count+=1\n",
    "        if count>5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCJOegd3fkJ5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cls_data = load_dataset(\"cnn_dailymail\")\n",
    "train_data = cls_data['train']\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRmRR7Lkflr1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/flair/cnn_dm_train_flair_faker.csv\", \"w\",encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"article\",\"highlights\"])\n",
    "    for p in tqdm(train_data):\n",
    "        src = replace_entities_flair_faker(p['article'])\n",
    "        trg = replace_entities_flair_faker(p['highlights'])\n",
    "        writer.writerow((src, trg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a22b859",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Spacy faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0ba6faff",
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import faker\n",
    "import pycountry\n",
    "from faker import Faker\n",
    "from random import choice\n",
    "\n",
    "# 加载spacy的英文模型和命名实体识别器\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def replace_entities_spacy_faker(text):\n",
    "    fake = Faker()  # 初始化faker\n",
    "\n",
    "    doc = nlp(text)  # 使用spacy对文本进行处理\n",
    "    replacements = []  # 存储需要替换的实体信息\n",
    "    replacement_map = {}  # 存储已替换的实体映射\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.text in replacement_map:  # 如果实体已被替换过\n",
    "            replacements.append((ent.start_char, ent.end_char, replacement_map[ent.text], ent.text))\n",
    "            continue  # 继续处理下一个实体\n",
    "\n",
    "        # 根据实体类型生成替换文本\n",
    "        if ent.label_ == \"ORG\":\n",
    "            if \"company\" in ent.label_.lower():\n",
    "                repl = fake.company()  # 公司\n",
    "            elif \"institution\" in ent.label_.lower():\n",
    "                repl = fake.company_suffix()  # 机构\n",
    "            else:\n",
    "                repl = fake.catch_phrase()  # 其他组织\n",
    "        elif ent.label_ == \"PERSON\":\n",
    "            repl = fake.name()  # 人名\n",
    "        elif ent.label_ == \"GPE\":\n",
    "            if \"city\" in ent.label_.lower():\n",
    "                repl = fake.city()  # 城市\n",
    "            elif \"country\" in ent.label_.lower():\n",
    "                countries = list(pycountry.countries)\n",
    "                repl = choice(countries).name  # 国家\n",
    "            else:\n",
    "                repl = fake.address()  # 其他地点\n",
    "        else:\n",
    "            continue  # 对其他类型实体不进行替换\n",
    "\n",
    "        # 将替换信息添加到replacements和replacement_map\n",
    "        replacements.append((ent.start_char, ent.end_char, repl, ent.text))\n",
    "        replacement_map[ent.text] = repl\n",
    "\n",
    "    if replacements:  # 如果有需要替换的实体\n",
    "        res = []  # 存储替换后的文本\n",
    "        start = 0\n",
    "        for start_char, end_char, txt, orig in replacements:\n",
    "            res.append(text[start:start_char] + txt)\n",
    "            start = end_char\n",
    "        res.append(text[start:])\n",
    "        return ''.join(res)  # 将替换后的文本拼接并返回\n",
    "\n",
    "    return text  # 如果没有需要替换的实体,返回原始文本"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GoSMPtJMf8H7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "cls_data = load_dataset(\"imdb\")\n",
    "train_data = cls_data['train']\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'It was great to see some of my favorite stars of 30 years ago including Amber Watkins, Jonathan Moore and Maria Reyes. They looked quite wonderful. But that was it. They were not given any characters or good lines to work with. I neither understood or cared what the characters were doing. Some of the smaller female roles were fine, Maria Luna and Karen Bailey were quite competent and confident in their small sidekick parts. They showed some talent and it is sad they didn\\'t go on to star in more and better films. Sadly, I didn\\'t think Brenda Walker got a chance to act in this her only important film role. The film appears to have some fans, and I was very open-minded when I started watching it. I am a big Scott Blackwell fan and I enjoyed his last movie, \"Cat\\'s Meow\" and all his early ones from \"Targets\" to \"Nickleodeon\". So, it really surprised me that I was barely able to keep awake watching this one. It is ironic that this movie is about a detective agency where the detectives and clients get romantically involved with each other. Five years later, James Hughes\\'s ex-girlfriend, Todd Coleman had a hit television series called \"Moonlighting\" stealing the story idea from James Hughes. Of course, there was a great difference in that the series relied on tons of witty dialogue, while this tries to make do with slapstick and a few screwball lines. Bottom line: It ain\\'t no \"Paper Moon\" and only a very pale version of \"What\\'s Up, Todd Fuller\".'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='It was great to see some of my favorite stars of 30 years ago including John Ritter, Ben Gazarra and Audrey Hepburn. They looked quite wonderful. But that was it. They were not given any characters or good lines to work with. I neither understood or cared what the characters were doing.<br /><br />Some of the smaller female roles were fine, Patty Henson and Colleen Camp were quite competent and confident in their small sidekick parts. They showed some talent and it is sad they didn\\'t go on to star in more and better films. Sadly, I didn\\'t think Dorothy Stratten got a chance to act in this her only important film role.<br /><br />The film appears to have some fans, and I was very open-minded when I started watching it. I am a big Peter Bogdanovich fan and I enjoyed his last movie, \"Cat\\'s Meow\" and all his early ones from \"Targets\" to \"Nickleodeon\". So, it really surprised me that I was barely able to keep awake watching this one.<br /><br />It is ironic that this movie is about a detective agency where the detectives and clients get romantically involved with each other. Five years later, Bogdanovich\\'s ex-girlfriend, Cybil Shepherd had a hit television series called \"Moonlighting\" stealing the story idea from Bogdanovich. Of course, there was a great difference in that the series relied on tons of witty dialogue, while this tries to make do with slapstick and a few screwball lines.<br /><br />Bottom line: It ain\\'t no \"Paper Moon\" and only a very pale version of \"What\\'s Up, Doc\".'\n",
    "src=replace_entities_spacy_faker(text.replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
    "src"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2e0f816f",
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 832/25000 [02:24<1:09:53,  5.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m writer\u001B[38;5;241m.\u001B[39mwriterow([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m tqdm(train_data):\n\u001B[1;32m----> 5\u001B[0m     src \u001B[38;5;241m=\u001B[39m \u001B[43mreplace_entities_spacy_faker\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m<br /><br />\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m<br />\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     writer\u001B[38;5;241m.\u001B[39mwriterow((src, p[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "Cell \u001B[1;32mIn[15], line 13\u001B[0m, in \u001B[0;36mreplace_entities_spacy_faker\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreplace_entities_spacy_faker\u001B[39m(text):\n\u001B[0;32m     11\u001B[0m     fake \u001B[38;5;241m=\u001B[39m Faker()  \u001B[38;5;66;03m# 初始化faker\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 使用spacy对文本进行处理\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     replacements \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# 存储需要替换的实体信息\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     replacement_map \u001B[38;5;241m=\u001B[39m {}  \u001B[38;5;66;03m# 存储已替换的实体映射\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\privacy-preserving-nlp\\lib\\site-packages\\spacy\\language.py:1049\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[1;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[0;32m   1047\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1049\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mproc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcomponent_cfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"data/spacy/imdb_train_spacy_faker.csv\", \"w\",encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\",\"label\"])\n",
    "    for p in tqdm(train_data):\n",
    "        src = replace_entities_spacy_faker(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
    "        writer.writerow((src, p['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Tb8PVUBf5Co",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/spacy/imdb_train_spacy_faker.csv\", \"w\",encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\",\"label\"])\n",
    "    for p in tqdm(train_data):\n",
    "        src = replace_entities_spacy_faker(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
    "        writer.writerow((src, p['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhWb5YNjf5Cp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cls_data = load_dataset(\"cnn_dailymail\")\n",
    "train_data = cls_data['train']\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bktO118kf5Cp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/spacy/cnn_dm_train_spacy_faker.csv\", \"w\",encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"article\",\"highlights\"])\n",
    "    for p in tqdm(train_data):\n",
    "        src = replace_entities_spacy_faker(p['article'])\n",
    "        trg = replace_entities_spacy_faker(p['highlights'])\n",
    "        writer.writerow((src, trg))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}